{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Email Classification with PII Masking and API Deployment\n",
        "\n",
        "##Introduction\n",
        "\n",
        "In today's fast-paced digital environment, customer support teams often deal with a large volume of emails. Automatically classifying these emails into predefined categories can significantly streamline workflows and improve response times. Additionally, to ensure data privacy and regulatory compliance, it is essential to mask personally identifiable information (PII) before any data processing.\n",
        "\n",
        "##Objective\n",
        "\n",
        "The objective of this project is to build an end-to-end email classification system that:\n",
        "- **Masks personal information (PII)** such as name, email, phone number, etc.\n",
        "- **Classifies support emails** into categories like Billing Issues, Technical Support, etc.\n",
        "- **Restores the original data** after classification\n",
        "- **Exposes the system through an API** for real-time usage\n",
        "\n",
        "##Problem Scope\n",
        "\n",
        "The system must:\n",
        "1. Detect and mask the following PII entities (without using LLMs):\n",
        "   - Full Name (`full_name`)\n",
        "   - Email Address (`email`)\n",
        "   - Phone Number (`phone_number`)\n",
        "   - Date of Birth (`dob`)\n",
        "   - Aadhar Card Number (`aadhar_num`)\n",
        "   - Credit/Debit Card Number (`credit_debit_no`)\n",
        "   - CVV Number (`cvv_no`)\n",
        "   - Expiry Number (`expiry_no`)\n",
        "2. Classify emails using any suitable model (ML/DL/LLM)\n",
        "3. Accept user input and return a structured response via a **POST API**\n",
        "\n",
        "##Workflow\n",
        "\n",
        "1. Data Loading and Preprocessing  \n",
        "2. PII Detection and Masking (Regex / NER / Custom NLP)  \n",
        "3. Email Classification (Model training and prediction)  \n",
        "4. Demasking and Output Formatting  \n",
        "5. API Development and Deployment  \n",
        "\n",
        "---\n",
        "\n",
        "Let’s begin with the necessary imports and initial setup.\n"
      ],
      "metadata": {
        "id": "WMxwKJmQNvwZ"
      },
      "id": "WMxwKJmQNvwZ"
    },
    {
      "cell_type": "markdown",
      "id": "c4351ec1",
      "metadata": {
        "id": "c4351ec1"
      },
      "source": [
        "\n",
        "\n",
        "##  Environment Setup\n",
        "\n",
        "Before starting with the implementation, we need to install and configure the required libraries which ensure that our environment is ready for email processing, PII masking, and API deployment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14256727",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14256727",
        "outputId": "29573b89-db72-46a5-f256-bd7d673762c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.9-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.34.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.9-py3-none-any.whl (25 kB)\n",
            "Downloading uvicorn-0.34.3-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, pyngrok, starlette, fastapi\n",
            "Successfully installed fastapi-0.115.12 pyngrok-7.2.9 starlette-0.46.2 uvicorn-0.34.3\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.6)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install fastapi nest-asyncio pyngrok uvicorn\n",
        "!pip install scikit-learn pandas joblib spacy\n",
        "!python -m spacy download en_core_web_sm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf73d4c7",
      "metadata": {
        "id": "bf73d4c7"
      },
      "source": [
        "### Step 1: Importing the Required Libraries\n",
        "\n",
        "To begin with, we import all the necessary Python libraries that will support various parts of our project. We use `re` for regular expressions, which will help us detect and mask personal information like emails or phone numbers. `spacy` is imported for natural language processing tasks, especially useful in identifying named entities such as names or dates of birth. For handling and analyzing data, we use `pandas`.\n",
        "\n",
        "We also import several modules from `scikit-learn` which will be used for building and evaluating our email classification models. These include vectorizers like `TfidfVectorizer`, classifiers such as `MultinomialNB` and `SVC`, and utility functions like `train_test_split` and `classification_report`. `joblib` will help us save and reload our trained models later.\n",
        "\n",
        "Since this project includes creating an API for real-time interaction, we use `FastAPI` and `BaseModel` to define and deploy the API endpoints. Running an API inside a notebook isn't straightforward, so we use `nest_asyncio` and `pyngrok` to allow asynchronous execution and make the API publicly accessible via a tunnel. Finally, `uvicorn` is included to serve the FastAPI app.\n",
        "\n",
        "This setup ensures that we have all the tools needed for building a robust pipeline — from data preprocessing and classification to deploying an interactive API.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9453c097",
      "metadata": {
        "id": "9453c097"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import joblib\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.svm import SVC\n",
        "import sys\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c8b6f11",
      "metadata": {
        "id": "2c8b6f11"
      },
      "source": [
        "### Step 2: Creating the PII Masking Function\n",
        "\n",
        "In this section, we define a custom function named `mask_pii` which is responsible for identifying and masking Personally Identifiable Information (PII) from a given text. To do this effectively, we first load the small English language model from spaCy, which is well-suited for basic NLP tasks like named entity recognition.\n",
        "\n",
        "The function works in two stages. First, it uses regular expressions to detect common PII patterns such as email addresses, phone numbers, Aadhaar numbers, credit or debit card numbers, CVV codes, and expiration dates. When such information is found, it is replaced in the text with a label in square brackets (e.g., `[email]` or `[aadhar_num]`), and details about each masked item are recorded — including its position, type, and original content.\n",
        "\n",
        "In the second stage, we use spaCy’s NLP model to identify named entities in the text, focusing specifically on entities labeled as `PERSON` (which we treat as full names) and `DATE` (interpreted as dates of birth). These entities are also replaced with placeholders like `[full_name]` or `[dob]`.\n",
        "\n",
        "The function returns two items: the updated version of the text with all detected PII masked, and a list containing metadata for each masked item. This approach ensures that sensitive user information is hidden before any further analysis or processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b46bb283",
      "metadata": {
        "id": "b46bb283"
      },
      "outputs": [],
      "source": [
        "# Load the small English NLP model from spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def mask_pii(text):\n",
        "    # Make a copy of the input text\n",
        "    masked_text = text\n",
        "    masked_entities = []\n",
        "\n",
        "    # Define patterns for common types of PII (Personally Identifiable Information)\n",
        "    patterns = [\n",
        "        (r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', 'email'),\n",
        "        (r'\\b\\d{10}\\b', 'phone_number'),\n",
        "        (r'\\b\\d{4} \\d{4} \\d{4}\\b', 'aadhar_num'),\n",
        "        (r'\\b(?:\\d{4}[- ]?){3}\\d{4}\\b', 'credit_debit_no'),\n",
        "        (r'\\b\\d{3}\\b', 'cvv_no'),\n",
        "        (r'\\b(0[1-9]|1[0-2])\\/([0-9]{2}|[0-9]{4})\\b', 'expiry_no'),\n",
        "    ]\n",
        "\n",
        "    # Mask any matches from regex patterns\n",
        "    for pattern, label in patterns:\n",
        "        for match in re.finditer(pattern, masked_text):\n",
        "            entity_text = match.group()\n",
        "            start, end = match.start(), match.end()\n",
        "\n",
        "            # Replace the entity in text with its label\n",
        "            masked_text = masked_text.replace(entity_text, f\"[{label}]\", 1)\n",
        "\n",
        "            # Store masked entity info\n",
        "            masked_entities.append({\n",
        "                \"position\": [start, end],\n",
        "                \"classification\": label,\n",
        "                \"entity\": entity_text\n",
        "            })\n",
        "\n",
        "    # Use spaCy to detect named entities (like names and dates)\n",
        "    doc = nlp(text)\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"PERSON\":\n",
        "            label = \"full_name\"\n",
        "        elif ent.label_ == \"DATE\":\n",
        "            label = \"dob\"\n",
        "        else:\n",
        "            continue  # Skip other entity types\n",
        "\n",
        "        entity_text = ent.text\n",
        "        start, end = ent.start_char, ent.end_char\n",
        "\n",
        "        # Only replace if the entity still exists in the text\n",
        "        if entity_text in masked_text:\n",
        "            masked_text = masked_text.replace(entity_text, f\"[{label}]\", 1)\n",
        "\n",
        "            masked_entities.append({\n",
        "                \"position\": [start, end],\n",
        "                \"classification\": label,\n",
        "                \"entity\": entity_text\n",
        "            })\n",
        "\n",
        "    return masked_text, masked_entities\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e12066f",
      "metadata": {
        "id": "4e12066f"
      },
      "source": [
        "Next, we're loading our dataset into the program.\n",
        "Once the file is loaded using pandas.read_csv(), we immediately perform a basic data cleaning step. We use the dropna() function to remove any rows in the dataset where the email or type columns are missing. This ensures that we’re only working with complete and meaningful data for our analysis or model training.\n",
        "\n",
        "Finally, we use df.head() to preview the first few rows of the cleaned dataset so we can verify that the data looks correct and has been loaded successfully.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19d649b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "19d649b1",
        "outputId": "14510752-71d5-4307-a0bd-d567e3c62593"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               email      type\n",
              "0  Subject: Unvorhergesehener Absturz der Datenan...  Incident\n",
              "1  Subject: Customer Support Inquiry\\n\\nSeeking i...   Request\n",
              "2  Subject: Data Analytics for Investment\\n\\nI am...   Request\n",
              "3  Subject: Krankenhaus-Dienstleistung-Problem\\n\\...  Incident\n",
              "4  Subject: Security\\n\\nDear Customer Support, I ...   Request"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83bd49ee-da05-48c1-b146-e9825d881d69\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>email</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subject: Unvorhergesehener Absturz der Datenan...</td>\n",
              "      <td>Incident</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: Customer Support Inquiry\\n\\nSeeking i...</td>\n",
              "      <td>Request</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Subject: Data Analytics for Investment\\n\\nI am...</td>\n",
              "      <td>Request</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Subject: Krankenhaus-Dienstleistung-Problem\\n\\...</td>\n",
              "      <td>Incident</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: Security\\n\\nDear Customer Support, I ...</td>\n",
              "      <td>Request</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83bd49ee-da05-48c1-b146-e9825d881d69')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-83bd49ee-da05-48c1-b146-e9825d881d69 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-83bd49ee-da05-48c1-b146-e9825d881d69');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6a55f660-6b0f-4671-a54e-5fb79d88d6a9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a55f660-6b0f-4671-a54e-5fb79d88d6a9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6a55f660-6b0f-4671-a54e-5fb79d88d6a9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 24000,\n  \"fields\": [\n    {\n      \"column\": \"email\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24000,\n        \"samples\": [\n          \"Subject: Request for Support Regarding Possible Data Loss\\n\\nA possible data loss in the Medication Database has been identified. Investigations are ongoing to determine whether the cause is due to unauthorized access or system vulnerabilities. Access logs have been reviewed and temporary security measures have been implemented, but the issue persists My name is David Kim.. We kindly request assistance in resolving the problem to ensure the security of sensitive patient data. You can reach me at sophia.rossi@service.it.\",\n          \"Subject: Sicherer Datenspeichersystem\\n\\nLieber Kundendienst, ich hoffe, es geht Ihnen gut. Ich schreibe an Sie, um nachzufragen, ob es zu den aktuellen Entwicklungen in der sicheren Datenspeicherung und -\\u00fcbertragung von medizinischen Daten f\\u00fcr IT-Systeme und Ger\\u00e4te in Krankenh\\u00e4usern gekommen ist My name is Carlos Mendoza.. Da die Sicherheit medizinischer Daten von gro\\u00dfer Bedeutung ist, k\\u00f6nnte jede \\u00c4nderung an den Protokollen wichtige Auswirkungen auf Krankenh\\u00e4user und Gesundheitsversorger haben You can reach me at maria.gonzalez@shop.es.. Ich w\\u00fcrde mich freuen, mehr Informationen zu erhalten, einschlie\\u00dflich der vorgenommenen \\u00c4nderungen und den Vorteilen, die sie mit sich bringen. Insbesondere bin ich daran interessiert, zu verstehen, wie diese \\u00c4nderungen die Sicherheit und Effizienz der Datenspeicherung und -\\u00fcbertragung von medizinischen Daten verbessern werden. K\\u00f6nnten Sie mir bitte \\u00fcber diesen Themenbereich Auskunft geben? Ich freue mich auf Ihre R\\u00fcckmeldung und danke Ihnen f\\u00fcr Ihre Zeit und Unterst\\u00fctzung.\",\n          \"Subject: Verbesserte Projektverwaltung\\n\\nBekomplettieren Sie Wave Audio-Tool mit Trackball, um zus\\u00e4tzliche Funktionen und Kooperation zu erweitern. My contact number is +91-98765-43210.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Request\",\n          \"Change\",\n          \"Incident\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\n",
        "# Upload CSV manually via Colab file interface or use path below if already uploaded\n",
        "df = pd.read_csv(\"combined_emails_with_natural_pii.csv\")\n",
        "df = df.dropna(subset=[\"email\", \"type\"])  # drop rows with missing data\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f7aac69",
      "metadata": {
        "id": "0f7aac69"
      },
      "source": [
        "Now the dataset is first split into training and test sets, where 80% of the data is used to train the model and 20% is reserved for testing its performance. The TfidfVectorizer is then applied to convert the raw email text into numerical features by computing the term frequency-inverse document frequency (TF-IDF) scores for each word, which helps in emphasizing important terms while reducing the weight of commonly occurring ones. The transformed training data is then used to train a Multinomial Naive Bayes classifier, a popular choice for text classification tasks. Once the model is trained, predictions are made on the test data, and the performance is evaluated using accuracy and a classification report that provides precision, recall, and F1-score for each class. Finally, both the trained model and the vectorizer are saved using joblib, allowing them to be reused later in a deployment scenario without needing to retrain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ad6459f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ad6459f",
        "outputId": "2f3d8542-c73e-4711-9f60-4181a61a0af7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.66875\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Change       0.97      0.07      0.13       479\n",
            "    Incident       0.61      0.99      0.75      1920\n",
            "     Problem       0.38      0.01      0.02      1009\n",
            "     Request       0.78      0.91      0.84      1392\n",
            "\n",
            "    accuracy                           0.67      4800\n",
            "   macro avg       0.68      0.50      0.44      4800\n",
            "weighted avg       0.65      0.67      0.56      4800\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tfidf_vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[\"email\"], df[\"type\"], test_size=0.2, random_state=42)\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_vec, y_train)\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "joblib.dump(model, \"naive_bayes_model.pkl\")\n",
        "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This output summarizes the performance of the trained Naive Bayes model on the test dataset. The overall accuracy is 66.88%, which means that about two-thirds of the email types were correctly predicted. However, looking at the detailed classification report, it's clear that the model performs unevenly across different categories. For example, it does extremely well with \"Incident\" emails (high precision and recall), but performs poorly with \"Change\" and \"Problem\" types, barely identifying any of them correctly. The f1-scores for these underperforming categories are especially low, indicating a lack of balance between precision and recall. This imbalance could be due to class distribution or feature limitations. Finally, the line ['tfidf_vectorizer.pkl'] confirms that the TF-IDF vectorizer has been successfully saved to disk for future use."
      ],
      "metadata": {
        "id": "WOIaXZsVwLOD"
      },
      "id": "WOIaXZsVwLOD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, a Support Vector Machine (SVM) model with a linear kernel is trained on the same TF-IDF vectorized training data. The model is then used to make predictions on the test set. The performance is evaluated using accuracy and a detailed classification report, allowing comparison with the earlier Naive Bayes model. After evaluation, the trained SVM model is saved as svm_model.pkl, and the TF-IDF vectorizer is saved again as tfidf_vectorizer.pkl, ensuring that both components are available for future inference or deployment."
      ],
      "metadata": {
        "id": "QwdMJVHKyrW6"
      },
      "id": "QwdMJVHKyrW6"
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train_vec, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test_vec)\n",
        "\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "joblib.dump(svm_model, \"svm_model.pkl\")\n",
        "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4nRGt0zkPwI",
        "outputId": "1813555f-f573-42c9-f345-6b057f8553c6"
      },
      "id": "g4nRGt0zkPwI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.7729166666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Change       0.96      0.80      0.87       479\n",
            "    Incident       0.69      0.91      0.78      1920\n",
            "     Problem       0.65      0.28      0.39      1009\n",
            "     Request       0.91      0.94      0.92      1392\n",
            "\n",
            "    accuracy                           0.77      4800\n",
            "   macro avg       0.80      0.73      0.74      4800\n",
            "weighted avg       0.77      0.77      0.75      4800\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tfidf_vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce0440c1",
      "metadata": {
        "id": "ce0440c1"
      },
      "source": [
        "The performance metrics show that the Support Vector Machine (SVM) model significantly outperforms the earlier Naive Bayes model. With an overall accuracy of approximately 77%, the SVM handles most categories effectively. Notably, it achieves high precision and recall for classes like \"Request\" and \"Change\", indicating reliable classification in those categories. However, the \"Problem\" class still has relatively low recall, suggesting that many instances in this category are not being correctly identified. Overall, the model provides a better balance across categories compared to Naive Bayes, making it more suitable for practical deployment."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, a previously trained SVM model and TF-IDF vectorizer are loaded using joblib, which allows the model to be reused without retraining. The function classify_email_pipeline then defines a complete processing pipeline for an incoming email. It first calls the mask_pii function to anonymize any sensitive personal data in the email (like names, dates, and contact info), producing both the masked version of the text and a list of masked entities. The cleaned, masked text is then transformed into numerical features using the TF-IDF vectorizer. This vector is passed into the loaded SVM model, which predicts the email's category (such as \"Incident\", \"Request\", etc.). Finally, the function returns a dictionary containing the original email, the list of masked entities with their details, the masked email, and the predicted category—packaging the entire process into a reusable, production-ready pipeline.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ctZTUT2PzZnR"
      },
      "id": "ctZTUT2PzZnR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b181ad6b",
      "metadata": {
        "id": "b181ad6b"
      },
      "outputs": [],
      "source": [
        "model = joblib.load(\"svm_model.pkl\")\n",
        "vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")\n",
        "\n",
        "def classify_email_pipeline(email_text):\n",
        "    masked_text, masked_entities = mask_pii(email_text)\n",
        "    vector = vectorizer.transform([masked_text])\n",
        "    category = model.predict(vector)[0]\n",
        "    return {\n",
        "        \"input_email_body\": email_text,\n",
        "        \"list_of_masked_entities\": masked_entities,\n",
        "        \"masked_email\": masked_text,\n",
        "        \"category_of_the_email\": category\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 7: Run FastAPI with `pyngrok` in Colab"
      ],
      "metadata": {
        "id": "TEriAEtRoZfA"
      },
      "id": "TEriAEtRoZfA"
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken  YOUR_NGROK_AUTHTOKEN\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HYKqkgLnbkY",
        "outputId": "642127c7-0df2-43df-c90b-2a722fcd8d91"
      },
      "id": "4HYKqkgLnbkY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys.modules[\"main\"] = sys.modules[\"__main__\"]"
      ],
      "metadata": {
        "id": "VO0GKzrdqVAp"
      },
      "id": "VO0GKzrdqVAp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, sets up and launches a simple API using FastAPI directly from a Jupyter or Google Colab environment. First, an instance of the FastAPI app is created, and nest_asyncio.apply() is called to allow asynchronous event loops to run in notebooks without errors. Then, a data model EmailInput is defined using Pydantic to validate the structure of incoming data—specifically, the email body that needs classification. A POST endpoint /classify is created, which accepts email data, processes it through the classify_email_pipeline function, and returns the output including the masked content and predicted category. To make this locally hosted API accessible over the internet, ngrok is used to open a secure public tunnel on port 8000, and the public URL is printed for easy access. Finally, the FastAPI app is launched using uvicorn, which starts the server and listens for incoming requests. This setup makes it possible to interact with your email classification model via a web-based API interface from anywhere."
      ],
      "metadata": {
        "id": "Oln77P0O6OFk"
      },
      "id": "Oln77P0O6OFk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1660482",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1660482",
        "outputId": "5a49d431-5a76-4eae-e77e-69b9947c245b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public URL: NgrokTunnel: \"https://2cc1-35-231-75-185.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [236]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     2409:4073:29d:d089:258d:be7a:652d:86de:0 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "INFO:     2409:4073:29d:d089:258d:be7a:652d:86de:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     157.46.1.77:0 - \"GET / HTTP/1.1\" 404 Not Found\n"
          ]
        }
      ],
      "source": [
        "# Create API app\n",
        "app = FastAPI()\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Define input format\n",
        "class EmailInput(BaseModel):\n",
        "    email_body: str\n",
        "\n",
        "# Define route\n",
        "@app.post(\"/classify\")\n",
        "async def classify_email(data: EmailInput):\n",
        "    return classify_email_pipeline(data.email_body)\n",
        "\n",
        "# Open public tunnel with ngrok\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\"Public URL:\", public_url)\n",
        "\n",
        "# Run FastAPI app from this notebook\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}